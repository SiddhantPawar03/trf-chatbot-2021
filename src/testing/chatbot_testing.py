# -*- coding: utf-8 -*-
"""chatbot_testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10hGUXhp4aoU0jdS-J4wq3FhVQ6al-b-X
"""

from google.colab import drive 
drive.mount('/content/drive')

from tensorflow import keras
import random
import numpy as np
import pickle
import json

path = '/content/drive/MyDrive/Robosoft-ML/LSTM/new_datav4.json'

with open(path) as file : 
  data = json.load(file)

def chat():
    # load trained model
    chat_model = keras.models.load_model('/content/drive/MyDrive/Robosoft-ML/LSTM/bestv2.h5')

    # load tokenizer object
    with open('/content/drive/MyDrive/Robosoft-ML/LSTM/tokenizer.pickle', 'rb') as handle:
        tokenizer = pickle.load(handle)

    # load label encoder object
    with open('/content/drive/MyDrive/Robosoft-ML/LSTM/lbl_encoder.pickle', 'rb') as enc:
        onehot_encoded = pickle.load(enc)

    # parameters
    max_len = 10
    
    while True:
        
        inp = input()
        if inp.lower() == "quit":
            break

        result = chat_model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),
                                             truncating='post', maxlen=max_len))
        tag = onehot_encoded.inverse_transform([np.argmax(result)])
        

        for i in data['intents']:
            if i['tag'] == tag:
                print("ChatBot:", np.random.choice(i['responses']))
chat()

